{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version trains using the MNIST dataset, then tests on our own images\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.load('save_wih.npy')\n",
    "        #1) diem trung tam: 0.0    2) do rong (pow tra ve gia tri self.inodes luy thua -0.5)   3) hinh dang dau ra mang 200x784\n",
    "        self.who = numpy.load('save_who.npy')\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T #tao mang cua mang va dao mang ([a,b]->[[a],b])\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs) # nhan 2 ma tran trong so voi ma tran dau vao de dc gia tri tai cac nut lop an\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # thuc hien ham kich hoat signoid\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs) \n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "#training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "#training_data_list = training_data_file.readlines()\n",
    "#training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "#epochs = 10\n",
    "\n",
    "#for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "#    for record in training_data_list:\n",
    "#        # split the record by the ',' commas\n",
    "#        all_values = record.split(',') # chia chuoi thanh 1 chuoi loai bo dau ,\n",
    "#        # scale and shift the inputs\n",
    "#        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01 # quy mo dau vao pham vi 0,01 den 1\n",
    "#        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "#        targets = numpy.zeros(output_nodes) + 0.01 # tao ra 1 mang 0.01 (mang nay dien ta dau ra)\n",
    "#        # all_values[0] is the target label for this record\n",
    "#        targets[int(all_values[0])] = 0.99 # gan gia tri o thu all_values[0] - label cua mang dau ra la 0.99 tu la \n",
    "#        n.train(inputs, targets)\n",
    "#        pass\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with our own image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... my_own_images/9.png\n",
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.\n",
      " 1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.\n",
      " 1.   1.   1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.\n",
      " 0.01 0.01 1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   0.01\n",
      " 0.01 0.01 1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   0.01 0.01\n",
      " 0.01 0.01 1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   0.01 0.01 0.01\n",
      " 0.01 1.   1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01\n",
      " 0.01 1.   1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01\n",
      " 0.01 1.   1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01\n",
      " 1.   1.   1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   0.01 1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   1.   1.\n",
      " 1.   0.01 0.01 1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   0.01 0.01\n",
      " 0.01 0.01 1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 1.   1.   1.\n",
      " 1.   1.   1.   0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "min =  0.01\n",
      "max =  1.0\n",
      "[[0.01879259]\n",
      " [0.01543225]\n",
      " [0.0029501 ]\n",
      " [0.94894679]\n",
      " [0.00673989]\n",
      " [0.05060406]\n",
      " [0.00384853]\n",
      " [0.00371551]\n",
      " [0.00524725]\n",
      " [0.04945388]]\n",
      "network says  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "print (\"loading ... my_own_images/9.png\")\n",
    "img_array = imageio.imread('my_own_images/9.png', as_gray=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "print(img_data)\n",
    "print(\"min = \", numpy.min(img_data))\n",
    "print(\"max = \", numpy.max(img_data))\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
